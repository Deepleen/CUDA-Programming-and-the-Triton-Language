## Day 4

### 课程学习到的内容：

#### 作为调度单位的 Warp

- 每个 block 以 32-thread Warp 执行**（每个 warp 包含 32 个线程）**
  - 实施决策，而非 CUDA 编程模型的一部分
  - Warp 是 SM 中的调度单位
  - Warp 中的 thread 以 SIMD 方式执行
  - **未来的 GPU 可能会在每个 warp 中使用不同数量的 thread**

#### 线程调度

- SM 实现零开销 Warp 调度
  - 下一条指令的操作数已准备就绪的 Warp 可执行（如果数据未准备好（例如由于内存延迟），该 warp 将会停滞，SM 会调度另一个 warp 执行）
  - 符合条件的 warp 会根据优先调度策略被选择执行
  - 当一个 warp 被选中执行时，warp 内的所有线程执行相同的指令（这是因为 GPU 采用 SIMT（单指令多线程） 模型，虽然每个线程处理的数据可能不同，但它们共享相同的指令流，使得并行执行更加高效。）
    

### 一些概念的记录

#### 优化GPU性能的几个方面：

**1、并行度**

**a. Thread内部的指令级并行**

- 是什么：在现代GPU中，单个流处理器采用了**流水线**技术。Thread中当一条指令执行当前阶段时，另一条指令已经进入下一阶段。
- 如何实现：
  - 让线程尽可能多地执行**独立的算术运算**。
  - 编译器会自动尝试对代码进行指令调度，将没有依赖关系的指令尽可能靠近地放在一起，以填充流水线。
  - 程序员可以通过减少代码中的分支跳转、展开循环等方式来帮助编译器。

**b. Warp的并行 - Occupancy（占用率）**

- 是什么：**Occupancy**是一个量化指标，指每个SM上**活跃的Warp数量**与SM所能支持的**最大活跃Warp数量**之比。注意：每个SM的资源（寄存器、共享内存）是有限的。一个Block需要的资源越多，SM上能同时驻留的Block就越少，活跃的Warp也就越少，占用率就越低。
- 如何实现：
  - **优化资源使用**： 减少每个线程使用的寄存器数量（例如使用`__launch_bounds__`或编译器选项），或者减少每个Block使用的共享内存大小。
  - **调整Block大小**： 选择一个合适的Block线程数（例如128, 256, 512），使其能很好地被SM的资源所整除，从而最大化Warp的数量。

**c. SM间的并行 - 更多的Block**

- 是什么：让GPU的所有SM都参与到计算中来。如果一个Kernel只有一个很大的Block，那么它只能在一个SM上运行，其他SM都会闲置。
- 如何实现：
  - 在启动Kernel时，设置足够多的Grid和Block，即 `my_kernel<<<num_blocks, threads_per_block>>>()`，要确保 `num_blocks` 远大于GPU上SM的个数。
  - 通常建议启动的Block数量是SM数量的**好几倍甚至数十倍**，这样可以保证即使有些Block执行得快，有些执行得慢，也能始终有新的Block分配给空闲的SM，实现负载均衡。

**2、合并Memory访问**

- **是什么**： 当Warp中的线程访问Global Memory时，它们的请求会被合并成**尽可能少的事务**。
  - GPU的显存控制器不是以字节为单位读取，而是以**块**为单位（通常是32字节、64字节或128字节），这些块称为**Cache Line**或**Memory Segment**。
  - 理想情况是：一个Warp（32个线程）的32次访问（假设是4字节的`float`），恰好落在同一个或连续的几个32字节Cache Line内。这样，只需要1次或很少的几次内存事务，就可以服务整个Warp的请求。

- **如何实现**：
  - **确保线程访问连续的内存地址**： 这是最关键的一点。让`threadIdx.x`连续变化的线程访问的数组索引也是连续的。
  - 使用CUDA提供的工具（如Nsight Compute）来分析和验证内存访问模式。

**3、Warp内分支一致**

- **是什么**： 在一个Warp内部，所有32个线程最好能执行**相同的指令路径**。
  - 由于Warp是**单指令多线程**的执行模型，同一个Warp中的线程是**锁步**执行的。
  - 如果代码中存在`if-else`、`switch`等分支语句，并且Warp内的线程有的进入`if`块，有的进入`else`块，就会发生**分支分化**。

- **如何实现**：
  - **重构算法**： 尽量让数据（或数据布局）来决定控制流，确保同一个Warp内的数据具有相同的特性。例如，在排序后处理数据，或者使用“数据预制”策略，让需要执行相同分支的数据提前被分组到一起。
  - **使用谓词执行**： 有时编译器会将短的分支编译为**谓词执行**（即所有指令都执行，但只对符合条件的线程写入结果），这可以避免真正的分支分化，但会执行多余的指令。
  - 简单的规则：**确保if语句的条件在Warp内32个线程上的结果都相同**。