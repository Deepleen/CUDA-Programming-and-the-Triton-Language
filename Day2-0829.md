## Day 2

### 课程学习到的内容：

#### 指令集架构的概念：

硬件和软件之间的契约。对于每个软件，每当编写一段代码时，在CUDA中它最终会被编译成指令集架构。

#### 线程的层次：

使用**网格**（Grid）、**块**（Block）、**线程**（Thread）的三级结构，示意图如下所示：

![线程层次示意图](.\线程层次示意图.png)

注：线程是GPU上最小的执行单位，相当于一个核心执行的“最小任务”。一个线程处理一小块数据，比如**矩阵中的一个元素**。

#### GPU中的矩阵加法

**实现流程图如下所示**：

![GPU中矩阵加法的计算示意图](.\GPU中矩阵加法的计算示意图.png)

 **实现过程为：**

1、将输入矩阵块存放至存储至全局内存中。

2、将输出矩阵的每一个元素的计算任务分配给一个独立的线程。

3、多个线程同时启动，每个线程只执行一次加法操作，计算一个结果。

4、每个线程将结果写回全局内存中对应的位置。

**kernel代码和host代码**为：

```
// kernel Code
__global__ void vecAddKernel(float* A, float* B, float* C, int n)
{
    int i = threadIdx.x + blockDim.x * blockIdx.x;
    if(i < n) C[i] = A[i] + B[i];
}

// Host Code
void vecAdd(float* h_A, float* h_B, float* h_C, int n)
{
    // 运行 ceil(n/256.0) blocks，每个 block 包含 256 个 thread
    // ceil 函数可确保有足够的 thread 覆盖所有元素
    vecAddKernel<<<ceil(n/256.0), 256>>>(d_A, d_B, d_C, n);
}
```

其中threadIdx.x、blockDim.x和blockIdx.x是CUDA内置的变量。

#### CUDA设备内存管理API功能中的cudaMalloc()函数和cudaFree()函数

**1、cudaMalloc()函数 — 设备内存分配函数**

- 功能：在GPU的全局内存上动态分配指定大小的线性内存空间。注意：全局内存是GPU中容量最大、最常用的一种内存，所有线程都可以访问（但速度较慢）。
- 函数原型：cudaError_t cudaMalloc(void** devPtr, size_t size);
- 参数解释：
  - `void** devPtr`：这是一个**指向指针的指针**。函数执行成功后，系统会将分配好的设备内存的**起始地址**写入 `*devPtr` 所指向的那个指针变量。因此，你需要传入一个设备指针变量的地址。
  - `size_t size`：请求分配的字节数。通常使用 `sizeof()` 操作符来计算所需空间，例如 `sizeof(float) * N` 来表示分配N个单精度浮点数所需的空间。
- 返回值：返回一个 `cudaError_t` 类型的值，表示函数调用状态。如果分配成功，则返回 `cudaSuccess`。如果分配失败（例如，请求的内存太大，设备内存不足），则会返回相应的错误代码；`cudaMalloc` 返回的指针是**设备指针**。这个指针指向GPU上的内存，**不能在主机（CPU）代码中直接解引用**。主机与设备内存是分离的地址空间。

2、**cudaFree() — 设备内存释放函数**

- 功能：释放之前通过 `cudaMalloc()`（或其他CUDA内存分配函数，如 `cudaMallocPitch`）分配的设备内存。
- 函数原型：cudaError_t cudaFree(void* devPtr);

- 参数解释：
  - `void* devPtr`：要释放的设备内存的**起始地址**。这个地址必须是之前 `cudaMalloc()` 返回的地址。

- 返回值：同样返回 `cudaError_t` 状态码。如果释放成功，返回 `cudaSuccess`。如果传入的指针是无效的（例如，已经被释放过，或者是主机指针），则会返回错误。

#### 使用二维网格处理图片

在 GPU计算中，图像被划分为**多个小块**，每个小块由一个 block 进行处理。每个 block 内部包含多个 thread，这些 thread 协同工作以并行处理图像数据。

#### 处理图像（或其他二维数据的内核函数）的典型示例

```
// kernel Code
__global__ void PictureKernel(float* d_Pin, float* d_Pout, int height, int width)
{
    // 计算 d_Pin 和 d_Pout 元素的 row
    int Row = blockIdx.y * blockDim.y + threadIdx.y;
    
    // 计算 d_Pin 和 d_Pout 元素的 column
    int Col = blockIdx.x * blockDim.x + threadIdx.x;
    
    // 如果在范围内，每个 thread 计算 d_Pout 的一个元素
    if((Row < height) && (Col < width)){
        d_Pout[Row * width + Col] = 2.0 * d_Pin[Row * width + Col]; // 将每个 pixel 值缩放 2.0
    }
}

// Host Code
void vecAdd(float* d_Pin, float* d_Pout, int height, int width)
{
    // DimGrid:定义一个线程块（Block）的维度和大小
    // DimBlock:定义整个网格（Grid）的维度和大小，即需要启动多少个线程块
    dim3 DimGrid((width-1)/16 + 1, (width-1)/16 + 1, 1);
    dim3 DimBlock(16, 16, 1);
    PictureKernel<<<DimGrid, DimBlock>>>(d_Pin, d_Pout, width, width);
}
```



### 一些概念的记录

#### CUDA编程中的Host和Device:

- **Host（主机）**：指的就是你的**CPU**和它的**内存（RAM）**。
- **Device（设备）**：指的就是你的**NVIDIA GPU**和它的**显存（VRAM）**。

